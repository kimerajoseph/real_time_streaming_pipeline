{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.ssql(type=update)\n",
        "-- CREATE TABLE IN GLUE CATALOG TO STORE STREAMING DATA\n",
        "\n",
        "CREATE TABLE stock_table(\n",
        "    ticker VARCHAR(6),\n",
        "    price DOUBLE,\n",
        "    event_time TIMESTAMP(3),\n",
        "    WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND \n",
        "    )\n",
        "    PARTITIONED BY (ticker)\n",
        "    WITH(\n",
        "        'connector'='kinesis',\n",
        "        'stream'='my-input-stream',\n",
        "        'aws.region'='eu-west-1',\n",
        "        'scan.stream.initpos'='LATEST',\n",
        "        'format'='json',\n",
        "        'json.timestamp-format.standard'='ISO-8601'\n",
        "        \n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink\n",
        "// CREATE TWO UDFs (User Defined Functions) AND REGISTER THEM WITH OUR TABLE ENVIRONMENT\n",
        "\n",
        "import java.time.LocalDateTime\n",
        "import java.time.format.DateTimeFormatter._\n",
        "import java.time.ZoneOffset\n",
        "\n",
        "// CONVERT DATETIME TO SECONDS\n",
        "class DateTimeToEpoch extends ScalarFunction{\n",
        "    def eval(datetime:LocalDateTime) = datetime.toEpochSecond(ZoneOffset.UTC)\n",
        "}\n",
        "btenv.registerFunction(\"dt_to_epoch\", new DateTimeToEpoch())\n",
        "\n",
        "// CONVERT ALL STRINGS TO LOWER CASE\n",
        "class ScalarLowerCase extends ScalarFunction{\n",
        "    def eval(str: String) = str.toLowerCase\n",
        "}\n",
        "btenv.registerFunction(\"to_lower\", new ScalarLowerCase())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "\n",
        "# grab stock table\n",
        "# create a sliding window and emit results every 5 seconds over 1 minute for every window\n",
        "# group by ticker and use the UDF defined earlier\n",
        "\n",
        "input_table = st_env.from_path(\"stock_table\")\n",
        "\n",
        "new_table = input_table.window(Slide.over(\"1.minute\").every(\"5.seconds\").on(\"event_time\").alias(\"one_minute_window\")) \\\n",
        "            .group_by(\"one_minute_window, ticker\") \\\n",
        "            .select(\"to_lower(ticker) as ticker, price.max as max_price, dt_to_epoch(one_minute_window.end) as epoch_time\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "\n",
        "z.show(new_table, stream_type=\"update\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.ssql(type=update)\n",
        "\n",
        "SELECT * FROM stock_table\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "Examples"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
